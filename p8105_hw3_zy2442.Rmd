---
title: "Homework 3"
author: Zhongqi Yue
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1
```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and ... columns.

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```


Let's make a plot

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

Let's make a table!!

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```

Apples vs ice cream..

```{r}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```

## Problem 2

Load, tidy, and otherwise wrangle the data.

```{r}
accel_df= (
  read.csv("./data/accel_data.csv")%>% 
  janitor::clean_names() %>% 
    pivot_longer(
      activity_1:activity_1440,
      names_to = "minute_of_a_day",
      names_prefix = "activity",
      values_to = "activity_counts") %>% 
    mutate(
      weekday_vs_weekend = case_when(
        day != c("Saturday","Sunday") ~ "weekday",
        day == c("Saturday", "Sunday") ~ "weekend",
        TRUE                           ~ ""))
      
    )
```

After tidy the dataset, there are `r nrow(accel_df)` observations and `r ncol(accel_df)` variables, which are `r names(accel_df)`.

```{r}
accel_df= (
  read.csv("./data/accel_data.csv")%>% 
  janitor::clean_names() %>% 
    pivot_longer(
      activity_1:activity_1440,
      names_to = "minute_of_a_day",
      names_prefix = "activity",
      values_to = "activity_counts") %>% 
    mutate(
      weekday_vs_weekend = case_when(
        day != c("Saturday","Sunday") ~ "weekday",
        day == c("Saturday", "Sunday") ~ "weekend",
        TRUE                           ~ "")) %>% 
    group_by(week,day) %>% 
    summarize(total_activity = sum(activity_counts, na.rm = TRUE)) %>%
    mutate(activity_rank = min_rank(total_activity)) %>% 
    knitr::kable()
      )
```

There is no obvious trend over total activity for each day during these three weeks. However, to some degree, the total activity counts for Tuesday and Wednesday are relatively stable, which are always within 350000~470000 counts across these three weeks. Besides, the rank of the total activity also shows that the rank of Tuesday is relative stable compared to other days, which always ranks 2,3 or 4 within a week. 

